{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  job  marital  education  default  balance  housing  loan  contact  \\\n",
      "0       58    4        1          2        0     2143        1     0        2   \n",
      "1       44    9        2          1        0       29        1     0        2   \n",
      "2       33    2        1          1        0        2        1     1        2   \n",
      "3       47    1        1          3        0     1506        1     0        2   \n",
      "4       33   11        2          3        0        1        0     0        2   \n",
      "5       35    4        1          2        0      231        1     0        2   \n",
      "6       28    4        2          2        0      447        1     1        2   \n",
      "7       42    2        0          2        1        2        1     0        2   \n",
      "8       58    5        1          0        0      121        1     0        2   \n",
      "9       43    9        2          1        0      593        1     0        2   \n",
      "10      41    0        0          1        0      270        1     0        2   \n",
      "11      29    0        2          1        0      390        1     0        2   \n",
      "12      53    9        1          1        0        6        1     0        2   \n",
      "13      58    9        1          3        0       71        1     0        2   \n",
      "14      57    7        1          1        0      162        1     0        2   \n",
      "15      51    5        1          0        0      229        1     0        2   \n",
      "16      45    0        2          3        0       13        1     0        2   \n",
      "17      57    1        1          0        0       52        1     0        2   \n",
      "18      60    5        1          0        0       60        1     0        2   \n",
      "19      33    7        1          1        0        0        1     0        2   \n",
      "20      28    1        1          1        0      723        1     1        2   \n",
      "21      56    4        1          2        0      779        1     0        2   \n",
      "22      32    1        2          0        0       23        1     1        2   \n",
      "23      25    7        1          1        0       50        1     0        2   \n",
      "24      40    5        1          0        0        0        1     1        2   \n",
      "25      44    0        1          1        0     -372        1     0        2   \n",
      "26      39    4        2          2        0      255        1     0        2   \n",
      "27      52    2        1          1        0      113        1     1        2   \n",
      "28      46    4        2          1        0     -246        1     0        2   \n",
      "29      36    9        2          1        0      265        1     1        2   \n",
      "...    ...  ...      ...        ...      ...      ...      ...   ...      ...   \n",
      "45181   46    1        1          1        0     6879        0     0        0   \n",
      "45182   34    9        1          1        0      133        0     0        0   \n",
      "45183   70    5        1          0        0      324        0     0        0   \n",
      "45184   63    5        1          1        0     1495        0     0        0   \n",
      "45185   60    7        1          2        0     4256        1     0        0   \n",
      "45186   59   11        1          3        0     1500        0     0        0   \n",
      "45187   32    7        2          1        0     1168        1     0        0   \n",
      "45188   29    4        2          1        0      703        1     0        0   \n",
      "45189   25    7        2          1        0      199        0     0        0   \n",
      "45190   32    1        1          1        0      136        0     0        0   \n",
      "45191   75    5        0          2        0     3810        1     0        0   \n",
      "45192   29    4        2          2        0      765        0     0        0   \n",
      "45193   28    6        2          2        0      159        0     0        0   \n",
      "45194   59    4        1          2        0      138        1     1        0   \n",
      "45195   68    5        1          1        0     1146        0     0        0   \n",
      "45196   25    8        2          1        0      358        0     0        0   \n",
      "45197   36    4        2          1        0     1511        1     0        0   \n",
      "45198   37    4        1          2        0     1428        0     0        0   \n",
      "45199   34    1        2          1        0     1475        1     0        0   \n",
      "45200   38    9        1          1        0      557        1     0        0   \n",
      "45201   53    4        1          2        0      583        0     0        0   \n",
      "45202   34    0        2          1        0      557        0     0        0   \n",
      "45203   23    8        2          2        0      113        0     0        0   \n",
      "45204   73    5        1          1        0     2850        0     0        0   \n",
      "45205   25    9        2          1        0      505        0     1        0   \n",
      "45206   51    9        1          2        0      825        0     0        0   \n",
      "45207   71    5        0          0        0     1729        0     0        0   \n",
      "45208   72    5        1          1        0     5715        0     0        0   \n",
      "45209   57    1        1          1        0      668        0     0        1   \n",
      "45210   37    2        1          1        0     2971        0     0        0   \n",
      "\n",
      "       day  month  duration  campaign  pdays  previous  poutcome  y  \n",
      "0        5      8       261         1     -1         0         3  0  \n",
      "1        5      8       151         1     -1         0         3  0  \n",
      "2        5      8        76         1     -1         0         3  0  \n",
      "3        5      8        92         1     -1         0         3  0  \n",
      "4        5      8       198         1     -1         0         3  0  \n",
      "5        5      8       139         1     -1         0         3  0  \n",
      "6        5      8       217         1     -1         0         3  0  \n",
      "7        5      8       380         1     -1         0         3  0  \n",
      "8        5      8        50         1     -1         0         3  0  \n",
      "9        5      8        55         1     -1         0         3  0  \n",
      "10       5      8       222         1     -1         0         3  0  \n",
      "11       5      8       137         1     -1         0         3  0  \n",
      "12       5      8       517         1     -1         0         3  0  \n",
      "13       5      8        71         1     -1         0         3  0  \n",
      "14       5      8       174         1     -1         0         3  0  \n",
      "15       5      8       353         1     -1         0         3  0  \n",
      "16       5      8        98         1     -1         0         3  0  \n",
      "17       5      8        38         1     -1         0         3  0  \n",
      "18       5      8       219         1     -1         0         3  0  \n",
      "19       5      8        54         1     -1         0         3  0  \n",
      "20       5      8       262         1     -1         0         3  0  \n",
      "21       5      8       164         1     -1         0         3  0  \n",
      "22       5      8       160         1     -1         0         3  0  \n",
      "23       5      8       342         1     -1         0         3  0  \n",
      "24       5      8       181         1     -1         0         3  0  \n",
      "25       5      8       172         1     -1         0         3  0  \n",
      "26       5      8       296         1     -1         0         3  0  \n",
      "27       5      8       127         1     -1         0         3  0  \n",
      "28       5      8       255         2     -1         0         3  0  \n",
      "29       5      8       348         1     -1         0         3  0  \n",
      "...    ...    ...       ...       ...    ...       ...       ... ..  \n",
      "45181   15      9        74         2    118         3         0  0  \n",
      "45182   15      9       401         2    187         5         2  1  \n",
      "45183   15      9        78         1     96         7         2  0  \n",
      "45184   16      9       138         1     22         5         2  0  \n",
      "45185   16      9       200         1     92         4         2  1  \n",
      "45186   16      9       280         1    104         2         0  0  \n",
      "45187   16      9       411         1     -1         0         3  1  \n",
      "45188   16      9       236         1    550         2         2  1  \n",
      "45189   16      9       173         1     92         5         0  0  \n",
      "45190   16      9       206         1    188         3         2  1  \n",
      "45191   16      9       262         1    183         1         0  1  \n",
      "45192   16      9       238         1     -1         0         3  1  \n",
      "45193   16      9       449         2     33         4         2  1  \n",
      "45194   16      9       162         2    187         5         0  0  \n",
      "45195   16      9       212         1    187         6         2  1  \n",
      "45196   16      9       330         1     -1         0         3  1  \n",
      "45197   16      9       270         1     -1         0         3  1  \n",
      "45198   16      9       333         2     -1         0         3  0  \n",
      "45199   16      9      1166         3    530        12         1  0  \n",
      "45200   16      9      1556         4     -1         0         3  1  \n",
      "45201   17      9       226         1    184         4         2  1  \n",
      "45202   17      9       224         1     -1         0         3  1  \n",
      "45203   17      9       266         1     -1         0         3  1  \n",
      "45204   17      9       300         1     40         8         0  1  \n",
      "45205   17      9       386         2     -1         0         3  1  \n",
      "45206   17      9       977         3     -1         0         3  1  \n",
      "45207   17      9       456         2     -1         0         3  1  \n",
      "45208   17      9      1127         5    184         3         2  1  \n",
      "45209   17      9       508         4     -1         0         3  0  \n",
      "45210   17      9       361         2    188        11         1  0  \n",
      "\n",
      "[45211 rows x 17 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_bank=pd.read_csv('https://raw.githubusercontent.com/PHBS/2017.M3.TQF-ML/master/files/DataSet1/bank-full.csv', encoding = 'latin1', delimiter = ';')\n",
    "le=LabelEncoder()\n",
    "df_bank['marital']=le.fit_transform(df_bank['marital'].astype('str'))\n",
    "df_bank['job']=le.fit_transform(df_bank['job'].astype('str'))\n",
    "df_bank['education']=le.fit_transform(df_bank['education'].astype('str'))\n",
    "df_bank['default']=le.fit_transform(df_bank['default'].astype('str'))\n",
    "df_bank['housing']=le.fit_transform(df_bank['housing'].astype('str'))\n",
    "df_bank['loan']=le.fit_transform(df_bank['loan'].astype('str'))\n",
    "df_bank['contact']=le.fit_transform(df_bank['contact'].astype('str'))\n",
    "df_bank['month']=le.fit_transform(df_bank['month'].astype('str'))\n",
    "df_bank['poutcome']=le.fit_transform(df_bank['poutcome'].astype('str'))\n",
    "df_bank['y']=le.fit_transform(df_bank['y'].astype('str'))\n",
    "print(df_bank)\n",
    "df_bank.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31647, 3) (31647,)\n",
      "(13564, 3) (13564,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1=df_bank[['age','education','balance']]\n",
    "y = df_bank.y\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(x1,y, test_size=0.3, random_state=7)\n",
    "\n",
    "print (X1_train.shape, y1_train.shape)\n",
    "print (X1_test.shape, y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X1_train)\n",
    "X1_train_std = sc.transform(X1_train)\n",
    "X1_test_std = sc.transform(X1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 7395\n",
      "Accuracy: 0.45\n",
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "#Perceptron\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=7)\n",
    "ppn.fit(X1_train_std, y1_train)\n",
    "y1_pred = ppn.predict(X1_test_std)\n",
    "print('Misclassified samples: %d' % (y1_test != y1_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y1_test, y1_pred))\n",
    "print('Accuracy: %.2f' % ppn.score(X1_test_std, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813473630991879"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines Linear\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X1_train_std, y1_train)\n",
    "y1_pred = svm.predict(X1_test_std)\n",
    "accuracy_svm = svm.score(X1_train_std, y1_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.78"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X1_train_std, y1_train)\n",
    "y1_pred = decision_tree.predict(X1_test_std)\n",
    "accuracy_decision_tree = round(decision_tree.score(X1_train_std, y1_train) * 100, 2)\n",
    "accuracy_decision_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.76"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X1_train_std, y1_train)\n",
    "y1_pred = random_forest.predict(X1_test_std)\n",
    "random_forest.score(X1_train_std, y1_train)\n",
    "accuracy_random_forest = round(random_forest.score(X1_train_std, y1_train) * 100, 2)\n",
    "accuracy_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8813473630991879"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X1_train_std, y1_train)\n",
    "y1_pred = sgd.predict(X1_test_std)\n",
    "accuracy_sgd = sgd.score(X1_train_std, y1_train) \n",
    "accuracy_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892754447498973"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines Radial\n",
    "svm = SVC(kernel='rbf', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X1_train_std, y1_train)\n",
    "y1_pred = svm.predict(X1_test_std)\n",
    "accuracy_svm = svm.score(X1_train_std, y1_train)\n",
    "accuracy_svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813157645274433"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "lr = LogisticRegression(C=1000.0, random_state=7) \n",
    "lr.fit(X1_train_std, y1_train)\n",
    "y1_pred = lr.predict(X1_test_std)\n",
    "accuracy_lr = lr.score(X1_train_std, y1_train)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940815875122444"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(X1_train_std, y1_train)\n",
    "y1_pred = knn.predict(X1_test_std)\n",
    "accuracy_knn = knn.score(X1_train_std, y1_train) \n",
    "accuracy_knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X1_train_std, y1_train)\n",
    "y1_pred = gaussian.predict(X1_test_std)\n",
    "accuracy_nb = gaussian.score(X1_train_std, y1_train)\n",
    "accuracy_nb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31647, 3) (31647,)\n",
      "(13564, 3) (13564,)\n"
     ]
    }
   ],
   "source": [
    "x2=df_bank[['loan','balance','default']]\n",
    "y = df_bank.y\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(x2,y, test_size=0.3, random_state=7)\n",
    "\n",
    "print (X2_train.shape, y1_train.shape)\n",
    "print (X2_test.shape, y1_test.shape)\n",
    "sc.fit(X2_train)\n",
    "X2_train_std = sc.transform(X2_train)\n",
    "X2_test_std = sc.transform(X2_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8813473630991879"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X2_train_std, y2_train)\n",
    "y2_pred = sgd.predict(X2_test_std)\n",
    "accuracy_sgd = sgd.score(X2_train_std, y2_train) \n",
    "accuracy_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8816001516731444"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines Radial\n",
    "svm = SVC(kernel='rbf', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X2_train_std, y2_train)\n",
    "y2_pred = svm.predict(X2_test_std)\n",
    "accuracy_svm = svm.score(X2_train_std, y2_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813473630991879"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines linear\n",
    "svm = SVC(kernel='linear', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X2_train_std, y2_train)\n",
    "y2_pred = svm.predict(X2_test_std)\n",
    "accuracy_svm = svm.score(X2_train_std, y2_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 10025\n",
      "Accuracy: 0.26\n",
      "Accuracy: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=7)\n",
    "ppn.fit(X2_train_std, y2_train)\n",
    "y2_pred = ppn.predict(X2_test_std)\n",
    "print('Misclassified samples: %d' % (y2_test != y2_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y2_test, y2_pred))\n",
    "print('Accuracy: %.2f' % ppn.score(X2_test_std, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9024236104528075"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X2_train_std, y2_train)\n",
    "y2_pred = decision_tree.predict(X2_test_std)\n",
    "accuracy_decision_tree = decision_tree.score(X2_train_std, y2_train) \n",
    "accuracy_decision_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812841659556988"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "lr = LogisticRegression(C=1000.0, random_state=7) \n",
    "lr.fit(X2_train_std, y2_train)\n",
    "y2_pred = lr.predict(X2_test_std)\n",
    "accuracy_lr = lr.score(X2_train_std, y2_train)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859607545738932"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(X2_train_std, y2_train)\n",
    "y2_pred = knn.predict(X2_test_std)\n",
    "accuracy_knn = knn.score(X2_train_std, y2_train) \n",
    "accuracy_knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902392011881063"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X2_train_std, y2_train)\n",
    "y2_pred = random_forest.predict(X2_test_std)\n",
    "random_forest.score(X2_train_std, y2_train)\n",
    "accuracy_random_forest = random_forest.score(X2_train_std, y2_train) \n",
    "accuracy_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703826587038266"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X2_train_std, y2_train)\n",
    "y2_pred = gaussian.predict(X2_test_std)\n",
    "accuracy_nb = gaussian.score(X2_train_std, y2_train)\n",
    "accuracy_nb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31647, 3) (31647,)\n",
      "(13564, 3) (13564,)\n"
     ]
    }
   ],
   "source": [
    "x3=df_bank[['default','education','balance']]\n",
    "y = df_bank.y\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(x3,y, test_size=0.3, random_state=7)\n",
    "\n",
    "print (X3_train.shape, y1_train.shape)\n",
    "print (X3_test.shape, y1_test.shape)\n",
    "sc.fit(X3_train)\n",
    "X3_train_std = sc.transform(X3_train)\n",
    "X3_test_std = sc.transform(X3_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165797705943691"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X3_train_std, y3_train)\n",
    "y3_pred = random_forest.predict(X3_test_std)\n",
    "random_forest.score(X3_train_std, y3_train)\n",
    "accuracy_random_forest = random_forest.score(X3_train_std, y3_train) \n",
    "accuracy_random_forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8813473630991879"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X3_train_std, y3_train)\n",
    "y3_pred = sgd.predict(X3_test_std)\n",
    "accuracy_sgd = sgd.score(X3_train_std, y3_train) \n",
    "accuracy_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165797705943691"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X3_train_std, y3_train)\n",
    "y3_pred = decision_tree.predict(X3_test_std)\n",
    "accuracy_decision_tree = decision_tree.score(X3_train_std, y3_train) \n",
    "accuracy_decision_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8893102031788164"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(X3_train_std, y3_train)\n",
    "y3_pred = knn.predict(X3_test_std)\n",
    "accuracy_knn = knn.score(X3_train_std, y3_train) \n",
    "\n",
    "accuracy_knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812841659556988"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "lr = LogisticRegression(C=1000.0, random_state=7) \n",
    "lr.fit(X3_train_std, y3_train)\n",
    "y3_pred = lr.predict(X3_test_std)\n",
    "accuracy_lr = lr.score(X3_train_std, y3_train)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 11831\n",
      "Accuracy: 0.13\n",
      "Accuracy: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=7)\n",
    "ppn.fit(X3_train_std, y3_train)\n",
    "y3_pred = ppn.predict(X3_test_std)\n",
    "print('Misclassified samples: %d' % (y3_test != y3_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y3_test, y3_pred))\n",
    "print('Accuracy: %.2f' % ppn.score(X3_test_std, y3_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819477359623346"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines Radial\n",
    "svm = SVC(kernel='rbf', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X3_train_std, y3_train)\n",
    "y3_pred = svm.predict(X3_test_std)\n",
    "accuracy_svm = svm.score(X3_train_std, y3_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813473630991879"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines linear\n",
    "svm = SVC(kernel='linear', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X3_train_std, y3_train)\n",
    "y3_pred = svm.predict(X3_test_std)\n",
    "accuracy_svm = svm.score(X3_train_std, y3_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8712358201409296"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X3_train_std, y3_train)\n",
    "y3_pred = gaussian.predict(X3_test_std)\n",
    "accuracy_nb = gaussian.score(X3_train_std, y3_train)\n",
    "accuracy_nb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27126, 3) (31647,)\n",
      "(18085, 3) (13564,)\n"
     ]
    }
   ],
   "source": [
    "x4=df_bank[['job','duration','loan']]\n",
    "y = df_bank.y\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(x4,y, test_size=0.4, random_state=7)\n",
    "\n",
    "print (X4_train.shape, y1_train.shape)\n",
    "print (X4_test.shape, y1_test.shape)\n",
    "sc.fit(X4_train)\n",
    "X4_train_std = sc.transform(X4_train)\n",
    "X4_test_std = sc.transform(X4_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8831379488313795"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X4_train_std, y4_train)\n",
    "y1_pred = sgd.predict(X4_test_std)\n",
    "accuracy_sgd = sgd.score(X4_train_std, y4_train) \n",
    "accuracy_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858659588586596"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "lr = LogisticRegression(C=1000.0, random_state=7) \n",
    "lr.fit(X4_train_std, y4_train)\n",
    "y4_pred = lr.predict(X4_test_std)\n",
    "accuracy_lr = lr.score(X4_train_std, y4_train)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9355231143552312"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X4_train_std, y4_train)\n",
    "y1_pred = random_forest.predict(X4_test_std)\n",
    "random_forest.score(X4_train_std, y4_train)\n",
    "accuracy_random_forest = random_forest.score(X4_train_std, y4_train)\n",
    "accuracy_random_forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9002064440020644"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(X4_train_std, y4_train)\n",
    "y4_pred = knn.predict(X4_test_std)\n",
    "accuracy_knn = knn.score(X4_train_std, y4_train) \n",
    "accuracy_knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9355599793555998"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X4_train_std, y4_train)\n",
    "y4_pred = decision_tree.predict(X4_test_std)\n",
    "accuracy_decision_tree = decision_tree.score(X4_train_std, y4_train) \n",
    "accuracy_decision_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 2301\n",
      "Accuracy: 0.87\n",
      "Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=7)\n",
    "ppn.fit(X4_train_std, y4_train)\n",
    "y1_pred = ppn.predict(X4_test_std)\n",
    "print('Misclassified samples: %d' % (y4_test != y4_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y4_test, y4_pred))\n",
    "print('Accuracy: %.2f' % ppn.score(X4_test_std, y4_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8967042689670427"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines Radial\n",
    "svm = SVC(kernel='rbf', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X4_train_std, y4_train)\n",
    "y4_pred = svm.predict(X4_test_std)\n",
    "accuracy_svm = svm.score(X4_train_std, y4_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8820688638206886"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines linear\n",
    "svm = SVC(kernel='linear', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X4_train_std, y4_train)\n",
    "y4_pred = svm.predict(X4_test_std)\n",
    "accuracy_svm = svm.score(X4_train_std, y4_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8845019538450195"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X4_train_std, y4_train)\n",
    "y4_pred = gaussian.predict(X4_test_std)\n",
    "accuracy_nb = gaussian.score(X4_train_std, y4_train)\n",
    "accuracy_nb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22605, 3) (31647,)\n",
      "(22606, 3) (13564,)\n"
     ]
    }
   ],
   "source": [
    "x5=df_bank[['job','marital','balance']]\n",
    "y = df_bank.y\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(x5,y, test_size=0.5, random_state=7)\n",
    "\n",
    "print (X5_train.shape, y1_train.shape)\n",
    "print (X5_test.shape, y1_test.shape)\n",
    "sc.fit(X5_train)\n",
    "X5_train_std = sc.transform(X5_train)\n",
    "X5_test_std = sc.transform(X5_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581508515815085"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X5_train_std, y5_train)\n",
    "y1_pred = random_forest.predict(X5_test_std)\n",
    "random_forest.score(X5_train_std, y5_train)\n",
    "accuracy_random_forest = random_forest.score(X5_train_std, y5_train) \n",
    "accuracy_random_forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8833001548330015"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X5_train_std, y5_train)\n",
    "y5_pred = sgd.predict(X5_test_std)\n",
    "accuracy_sgd = sgd.score(X5_train_std, y5_train)\n",
    "accuracy_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581950895819509"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Decision Tree\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X5_train_std, y5_train)\n",
    "y5_pred = decision_tree.predict(X5_test_std)\n",
    "accuracy_decision_tree = decision_tree.score(X5_train_std, y5_train)\n",
    "accuracy_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8964388409643884"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "knn.fit(X5_train_std, y5_train)\n",
    "y5_pred = knn.predict(X5_test_std)\n",
    "accuracy_knn = knn.score(X5_train_std, y5_train) \n",
    "accuracy_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 3609\n",
      "Accuracy: 0.84\n",
      "Accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perfect\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "ppn = Perceptron(n_iter=50, eta0=0.1, random_state=7)\n",
    "ppn.fit(X5_train_std, y5_train)\n",
    "y1_pred = ppn.predict(X5_test_std)\n",
    "print('Misclassified samples: %d' % (y5_test != y5_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y5_test, y5_pred))\n",
    "print('Accuracy: %.2f' % ppn.score(X5_test_std, y5_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8832559168325592"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "lr = LogisticRegression(C=1000.0, random_state=7) \n",
    "lr.fit(X5_train_std, y5_train)\n",
    "y5_pred = lr.predict(X5_test_std)\n",
    "accuracy_lr = lr.score(X5_train_std, y5_train)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858659588586596"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines Radial\n",
    "svm = SVC(kernel='rbf', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X5_train_std, y5_train)\n",
    "y5_pred = svm.predict(X5_test_std)\n",
    "accuracy_svm = svm.score(X5_train_std, y5_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833001548330015"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines linear\n",
    "svm = SVC(kernel='linear', random_state=7, gamma=100.0, C=1.0)\n",
    "svm.fit(X5_train_std, y5_train)\n",
    "y5_pred = svm.predict(X5_test_std)\n",
    "accuracy_svm = svm.score(X5_train_std, y5_train)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744525547445255"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X5_train_std, y5_train)\n",
    "y5_pred = gaussian.predict(X5_test_std)\n",
    "accuracy_nb = gaussian.score(X5_train_std, y5_train)\n",
    "accuracy_nb                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
